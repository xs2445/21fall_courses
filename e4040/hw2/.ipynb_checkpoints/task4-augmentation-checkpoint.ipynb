{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2 - Task 4: Data Augmentation & Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important factors in neural network training include the size and quality of the training set. Since it is often not possible to get a clean and large enough dataset for training, one way to improve the network's robustness and generalization ability is to create 'fake' data by injecting random noise or to perform transformations on the available data. A technique which implements this strategy is called __data augmentation__ and has shown to be very effective.\n",
    "\n",
    "One thing to remember when you augment your data is to never change the correct label of a sample. For example, for hand-written digit dataset, flipping a letter 'b' ends up looking like a letter 'd', but you must keep the label for 'b'. So please choose the best augmentation methods for your dataset.\n",
    "\n",
    "In the last part of this task, we introduce __transfer learning__ in TensorFlow to you by showing a demo. Test time augmentation (TTA) as additional content in data augmentation is also introduced based on your experiences on previous parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** you will need to download the data for task 4, located in the liondrive [here](https://drive.google.com/drive/folders/1SLLr3sEiZCmldrhX46f9_Nhkd-7PmV_t). You should have two .csv files in the folder '__data__': '__sign_mnist_test.csv__' and '__sign_mnist_train.csv__'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import modules\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    os.system('pip install pandas')\n",
    "    import pandas as pd\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "For this task we will be using the Sign Language MNIST dataset. Examples are comprised of 28 x 28 greyscale images representing sign language letters. Note that while most sign letter are static symbols, the signs for J (9) and Z (25) include motions and are thus not included in this dataset.\n",
    "\n",
    "\n",
    "![image](https://s-media-cache-ak0.pinimg.com/564x/f9/68/ee/f968eece212b201510fd617c9cb70269.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Sign Language MNIST data.\n",
    "img_cols = 28\n",
    "img_rows = 28\n",
    "\n",
    "#Import data from csv using pandas DataFrame\n",
    "X_train = pd.read_csv(\"./data/sign_mnist_train.csv\")\n",
    "X_test = pd.read_csv(\"./data/sign_mnist_test.csv\")\n",
    "\n",
    "#Convert X_train,X_test from DataFrame to an array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "#First column of X_train is y_train, first column of X_test is y_test\n",
    "y_train = X_train[:,0]\n",
    "y_test = X_test[:,0]\n",
    "\n",
    "#Remove first column from X_train, X_test\n",
    "X_train = X_train[:,1:]\n",
    "X_test = X_test[:,1:]\n",
    "\n",
    "# Data organizations:\n",
    "# Train data: 27455 samples from original train set: 1~27455\n",
    "# Validation data: 1000 samples from original train set: 26455~27455\n",
    "# Test data: 7172 samples\n",
    "# We've vectorized the \n",
    "\n",
    "X_train = X_train.reshape(27455, -1)\n",
    "X_test = X_test.reshape(7172,-1)\n",
    "\n",
    "num_train = 26455\n",
    "num_validation = 1000\n",
    "num_dev = 128\n",
    "\n",
    "# The development set is used for augmentation practices.\n",
    "mask = np.random.choice(num_train, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "# Seperate Training set into a training set and a validation set\n",
    "X_val = X_train[num_train:]\n",
    "y_val = y_train[num_train:]\n",
    "X_train = X_train[:num_train]\n",
    "y_train = y_train[:num_train]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)\n",
    "\n",
    "print(\"Number of classes: {}\".format(len(set(y_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some original images\n",
    "\n",
    "Here we use Pyplot to draw any 16 samples from the __development set__ in a 4-by-4 grid.\n",
    "\n",
    "__Note__: Since we have vectorized our data, we need to reshape it into 28 x 28 greyscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the original data.\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(16):\n",
    "    ax = fig.add_subplot(4, 4, i+1)\n",
    "    ax.imshow(X_dev[i, :].reshape(28, 28), 'gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Automatic Batch Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want you to create an automatic image generator that does several kinds of data augmentations, and produces a batch of data consisting of random samples every time you call it. \n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Finish the functions of class __ImageGenerator__ in **utils/image_generator.py**. The code is fully commented with instructions.\n",
    "\n",
    "__Hint__: The python keywords __yield__ and __next__ can help you do some tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image_generator import ImageGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an ImageGenerator object using the __development set__, and use __show__ function to plot the top 16 original images.\n",
    "\n",
    "__Note__: We need to reshape your data as the demanding input format of the class __ImageGenerator__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_dev.shape)\n",
    "print(X_dev.reshape(-1,1,28,28).transpose(0,2,3,1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageGenerator(X_dev.reshape(-1,1,28,28).transpose(0,2,3,1), y_dev)\n",
    "gen.show(X_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase Brightness (demo)\n",
    "\n",
    "Increase the brightness of the original __development set__, and plot 16 images with noise added.(These images may not be the same as the above 16 images according to your choice of parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright = gen.brightness(1.5)\n",
    "gen.show(bright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal and Verical Flip (demo)\n",
    "\n",
    "Flip the original __development set__ as you like (horizontal, vertical, or both), and plot the top 16 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = gen.flip('v')\n",
    "gen.show(flipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Implement the funciton **translate()** in **utils/image_generator.py**. Shift the original __development set__ by several pixels in both directions, and plot the top 16 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Implement the function **rotate()** in **utils.image_generator.py**. Rotate the original __development set__ by several degrees and plot the top 16 images.### TODO: Your code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Noise\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Implement the function **add_noise()** in **utils.image_generator.py**. Inject random noise into the original __development set__, and plot 16 images with noise added. (These images may not be the same as the above 16 images according to your choice of parameters.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Augmentation + LeNet\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Now you have your own data generator. You have been provided a simplified LeNet model in __utils/neuralnets/cnn/model_LeNet.py__. In __utils/neuralnets/cnn/my_LeNet_trainer.py__ you will find two TODOs. \n",
    "\n",
    "The first TODO asks you to **prepare batches of augmented training data** using the ImageGenerator you completed in the previous section. When generating augmented data, it is important to think carefully about the changes you are making to the data and the effect those changes may have on their classification. For example, the sign for the letter G is as follows:\n",
    "\n",
    "![im](https://media.istockphoto.com/vectors/is-the-seventh-letter-of-the-alphabet-in-sign-language-vector-image-vector-id1209943258?k=6&m=1209943258&s=612x612&w=0&h=46JNhmLyb9qHjNiI7TGC9xKo7icHf7GEW6NA2Z25c6A=)\n",
    "\n",
    "Similarly, the sign for Q is \n",
    "\n",
    "![im2](https://data.formsbank.com/pdf_docs_html/35/354/35435/page_1_thumb_big.png).\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Before completing the TODOs in __utils/neuralnets/cnn/my_LeNet_trainer.py__, explain which augmentations, or combination of augmentations (brightness, horizontal flip, vertical flip, translation, rotation, noise, etc.) could create issues for the classifier in the context of the signs for G and Q. Are there any other augmentations of signs that could pose problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__Your answer here__:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO__:</span> Propose a series of augmentations (at least 4) from the functions we implemented to generate an augmented training set. Be sure to avoid the issues discussed above and include argument parameters for the augmentation functions.\n",
    "\n",
    "Ex:\n",
    "\n",
    "1. flip('v')\n",
    "2. brightness(1.5)\n",
    "3. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__Your answer here__:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO__:</span> Complete the function **batch_train_data()** in **utils/neuralnets/cnn/my_LeNet_trainer.py** with your proposed data augmnetations.\n",
    "\n",
    "<span style=\"color:red\">__TODO__:</span> Complete the function **train_epoch()** in **utils/neuralnets/cnn/my_LeNet_trainer.py**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Install tqdm__: tqdm is a fast, extensible progress meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X_train.reshape(-1,1,28,28).transpose(0,2,3,1)\n",
    "X_v = X_val.reshape(-1,1,28,28).transpose(0,2,3,1)\n",
    "\n",
    "print(X_t.shape)\n",
    "print(X_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.neuralnets.cnn.my_LeNet_trainer import MyLeNet_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO__:</span> train network using run method in MyLeNet_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add describe training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (demos): Transfer Learning and Test Time Augmentation (TTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last part of assignment 2 before we go to the kaggle competition. In this part, we will provide you with examples of transfer learning, as well as the last context of data augmentation: test time augmentation. We believe they are useful tools for task 5.\n",
    "\n",
    "__Note__: The network in demos is not guaranteed to be well-trained. __No points are set in this part__. Feel free to edit the scripts and tune the parameters by yourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "The intuition behind transfer learning is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. For a somewhat different problem, you can then take advantage of these learned feature maps without having to start from scratch and training a new large model on a large dataset.\n",
    "\n",
    "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. Generally, we have two ways to customize a pre-trained model:\n",
    "\n",
    "1. **Feature Extraction**: Use the representations learned by a previous network to extract meaningful features from new samples. You simply add a new classifier, which will be trained from scratch, on top of the pretrained model so that you can repurpose the feature maps learned previously for our dataset. However, the final, classification part of the pretrained model is specific to original classification task, and subsequently specific to the set of classes on which the model was trained. That means you do not need to (re)train the entire model. You \"freeze\" the base convolution network, and only train the newly added classifier layers. \n",
    "\n",
    "2. **Fine-Tuning**: Unfreezing a few of the top layers of a frozen model base and jointly training both the newly-added classifier layers and the last layers of the base model. This allows us to \"fine tune\" the higher-order feature representations in the base model in order to make them more relevant for the specific task.\n",
    "\n",
    "This example uses the base model from __MobileNet__ for a transfer learning of a 10-class classification task on CIFAR-10 dataset. The whole pipeline will include:\n",
    "\n",
    "1. Load data\n",
    "2. Build an input pipeline, in this case using Keras ImageDataGenerator\n",
    "3. Compose our model\n",
    "4. Load in our pretrained base model (and pretrained weights)\n",
    "5. Stack our classification layers on top\n",
    "6. Train our model\n",
    "7. Evaluate model\n",
    "\n",
    "Other references: https://towardsdatascience.com/keras-transfer-learning-for-beginners-6c9b8b7143e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from utils.cifar_utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "X_train, y_train = load_data(mode='train')\n",
    "\n",
    "# Data organizations:\n",
    "# Train data: 49000 samples from original train set: 1~49000\n",
    "# Validation data: 1000 samples from original train set: 49000~50000\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "\n",
    "X_val = X_train[-num_validation:, :]\n",
    "y_val = y_train[-num_validation:]\n",
    "\n",
    "X_train = X_train[:num_training, :]\n",
    "y_train = y_train[:num_training]\n",
    "\n",
    "# Preprocessing: subtract the mean value across every dimension for training data, and reshape it to be RGB size\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train = X_train.astype(np.float32) - mean_image.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "\n",
    "X_train = X_train.reshape(-1,3,32,32).transpose(0,2,3,1) / 255\n",
    "X_val = X_val.reshape(-1,3,32,32).transpose(0,2,3,1) / 255\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "\n",
    "y_train_dummy = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_dummy = tf.keras.utils.to_categorical(y_val)\n",
    "print('Train labels shape (one-hot): ', y_train_dummy.shape)\n",
    "print('Validation labels shape (one-hot): ', y_val_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) \n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(10,activation='softmax')(x) #final layer with softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "#specify the inputs\n",
    "#specify the outputs\n",
    "#now a model has been created based on our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 98 #batch size\n",
    "epc = 25 #number of epoches\n",
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "train_generator = train_datagen.flow(X_train, y_train_dummy, batch_size=bs)\n",
    "step_size_train=train_generator.n//train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = model.fit_generator(generator = train_generator,\n",
    "                   steps_per_epoch = step_size_train,\n",
    "                   epochs = epc,\n",
    "                   validation_data=(X_val, y_val_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Baseline accuracy: {model.evaluate(X_val, y_val_dummy)[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Time Augmentation (TTA)\n",
    "\n",
    "Key references: \n",
    "\n",
    "https://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d\n",
    "\n",
    "https://machinelearningmastery.com/how-to-use-test-time-augmentation-to-improve-model-performance-for-image-classification/\n",
    "\n",
    "\n",
    "Data Augmentation is the process of randomly applying some operations (rotation, zoom, shift, flips,…) to the input data. By this mean, the model can learn more general features about the classes it has to recognize.\n",
    "\n",
    "However, there also exists some ways to improve the results of the model by changing the way we test it. That is Test Time Augmentation (TTA).\n",
    "\n",
    "TTA is now a commonly used technique in kaggle competition on classification. Similar to what data augmentation is doing to the training set, TTA is to perform similar data modifications to the test images. Thus, instead of showing the regular, “clean” images, only once to the trained model, we will show it the augmented images several times. The final guess of each corresponding image will base on the average of the prediction results.\n",
    "\n",
    "The reason why we refer to TTA is that, by averaging our predictions, on randomly modified images, we are also averaging the errors. The error can be big in a single vector, leading to a wrong answer, but when averaged, only the correct answer stand out. TTA is particularly useful for test images that the model is pretty unsure. The following example will show you how to apply TTA with Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call an ImageDataGenerator similar to training set for test set.\n",
    "test_datagen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=10.,\n",
    "        fill_mode='reflect', \n",
    "        width_shift_range = 0.1, \n",
    "        height_shift_range = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# test time augmentation, we set TTA for 10 times averaging.\n",
    "tta_steps = 10\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(tta_steps)):\n",
    "    preds = model.predict(test_datagen.flow(X_val, batch_size=bs, shuffle=False), steps = len(X_val)/bs)\n",
    "    predictions.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final prediction results\n",
    "final_pred = np.mean(predictions, axis=0)\n",
    "print(f'Accuracy with TTA: {np.mean(np.equal(np.argmax(y_val_dummy, axis=-1), np.argmax(final_pred, axis=-1)))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

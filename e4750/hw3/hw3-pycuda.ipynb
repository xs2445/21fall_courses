{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.gpuarray as gpuarray\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "\tdef __init__(self):\n",
    "\t\t# \"\"\"\n",
    "\t\t# Attributes for instance of EncoderDecoder module\n",
    "\t\t# \"\"\"\n",
    "\t\tself.mod = None\n",
    "\t\tpass\n",
    "\t\n",
    "\tdef getSourceModule(self, method):\n",
    "\t\t# kernel code wrapper\n",
    "\t\tkernelwrapper_naive = \"\"\"\n",
    "\t\t\t#include <stdio.h>\n",
    "\t\t\t__global__ \n",
    "\t\t\tvoid conv_gpu_naive(float *N, float *P, float *M, int height, int width, int mask_width){\n",
    "\n",
    "\t\t\t\t// the coordinate of thread (also coordinate in N or P)\n",
    "\t\t\t\tint col = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "\t\t\t\tint row = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "\n",
    "\t\t\t\t// copy to register\n",
    "\t\t\t\tint mask_w = mask_width;\n",
    "\t\t\t\tint n_w = width;\n",
    "\t\t\t\tint n_h = height;\n",
    "\t\t\t\t// start point of the kernel\n",
    "\t\t\t\tint col_start = col - mask_w/2;\n",
    "\t\t\t\tint row_start = row - mask_w/2;\n",
    "\n",
    "\t\t\t\tfloat p_value = 0.0f;\n",
    "\n",
    "\t\t\t\t// for every pixel in mask\n",
    "\t\t\t\tfor(int i=0; i<mask_w; i++){\n",
    "\t\t\t\t\t// x coordinate in N\n",
    "\t\t\t\t\tint row_i = row_start + i;\n",
    "\t\t\t\t\t// if in the range of N\n",
    "\t\t\t\t\tif(row_i>=0 && row_i<n_h){\n",
    "\t\t\t\t\t\tfor(int j=0; j<mask_w; j++){\n",
    "\t\t\t\t\t\t\t// y coordinate in N\n",
    "\t\t\t\t\t\t\tint col_i = col_start + j;\n",
    "\t\t\t\t\t\t\t// if in the range of N\n",
    "\t\t\t\t\t\t\tif(col_i>=0 && col_i<n_w){\n",
    "\t\t\t\t\t\t\t\tp_value += N[row_i*n_w+col_i] * M[mask_w*mask_w-(i*mask_w+j)-1];\n",
    "\t\t\t\t\t\t\t\t//int a = col_i*n_w+row_i;\n",
    "\t\t\t\t\t\t\t\t//printf(\"%d\", a);\n",
    "\t\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t\t//P[row*n_w+col] = N[row*n_w+col];\n",
    "\t\t\t\tP[row*n_w+col] = p_value;\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\t\"\"\" # you can either use a string or save the kernel in kernel.cu file and reference it here.\n",
    "\t\t# Compile the kernel code when an instance\n",
    "\t\t# of this class is made. \n",
    "\t\tif method == 'naive':\n",
    "\t\t\tmod = SourceModule(kernelwrapper_naive)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Please enter the correct method name! -naive\")\n",
    "\t\t\t\n",
    "\t\tself.mod = mod\n",
    "\n",
    "\tdef getBlockGridDim(self, N, blocksize=32):\n",
    "\t\tBlockDim = (blocksize, blocksize,1)\n",
    "\t\tGridDim = (N.shape[0]//blocksize+1, N.shape[1]//blocksize+1,1)\n",
    "\t\treturn BlockDim, GridDim\n",
    "\n",
    "\tdef conv_gpu_naive(self, N, M):\n",
    "\t\t\"\"\"\n",
    "\t\tconvolution with global memory\n",
    "\t\t:param N: input matrix\n",
    "\t\t:param M: mask\n",
    "\t\t:return:\n",
    "\t\t- out: a tensor with the same shape as x\n",
    "\t\t- cache: (train phase) cache a random dropout mask used in feedforward process\n",
    "\t\t\t\t(test phase) None\n",
    "\t\t\"\"\"\n",
    "\t\t# implement this, note you can change the function signature (arguments and return type)\n",
    "\t\t# convert the datatype\n",
    "\t\tN = N.astype(np.float32)\n",
    "\t\tM = M.astype(np.float32)\n",
    "\n",
    "\t\tself.getSourceModule('naive')\n",
    "\t\tfunc_conv = self.mod.get_function(\"conv_gpu_naive\")\n",
    "\t\theight, width = N.shape\n",
    "\t\t# print(height,width)\n",
    "\t\tmask_width = M.shape[0]\n",
    "\t\t# print(mask_width)\n",
    "\t\t# the result matrix\n",
    "\t\tP = np.empty_like(N)\n",
    "\t\t# copy to device global memory\n",
    "\t\tN_d = gpuarray.to_gpu(N)\n",
    "\t\tM_d = gpuarray.to_gpu(M)\n",
    "\t\tP_d = gpuarray.to_gpu(P)\n",
    "\t\t# block and grid size\n",
    "\t\tBlockDim, GridDim = self.getBlockGridDim(N)\n",
    "\n",
    "\t\tfunc_conv(N_d, P_d, M_d, np.int32(height), np.int32(width), np.int32(mask_width), block=BlockDim, grid = GridDim)\n",
    "\n",
    "\t\tP = P_d.get()\n",
    "\n",
    "\t\treturn P\n",
    "\n",
    "\n",
    "\tdef conv_gpu_shared_mem(self):\n",
    "\t\t# implement this, note you can change the function signature (arguments and return type)\n",
    "\t\tpass\n",
    "\n",
    "\tdef conv_gpu_shared_and_constant_mem(self):\n",
    "\t\t# implement this, note you can change the function signature (arguments and return type)\n",
    "\t\tpass\n",
    "\n",
    "\tdef test_conv_pycuda(self):\n",
    "\t\t# implement this, note you can change the function signature (arguments and return type)\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[[0.27530279 0.31653434 0.7534699  0.67114368 0.99024104]\n",
      " [0.00622994 0.72482204 0.3604693  0.78444885 0.45419031]\n",
      " [0.62593506 0.49758604 0.03948458 0.73805377 0.45162348]\n",
      " [0.93877677 0.01413113 0.31624175 0.16355324 0.04810857]\n",
      " [0.76496508 0.23980418 0.88955593 0.94045016 0.38946281]\n",
      " [0.07466562 0.33541515 0.28967001 0.03664556 0.65185675]] \n",
      "\n",
      "[[0.72482204 0.3604693  0.78444886 0.4541903  0.        ]\n",
      " [0.49758604 0.03948458 0.7380538  0.45162347 0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]] \n",
      "\n",
      "[[0.72482204 0.3604693  0.78444886 0.4541903  0.        ]\n",
      " [0.49758604 0.03948458 0.7380538  0.45162347 0.        ]\n",
      " [0.01413113 0.31624174 0.16355324 0.04810857 0.        ]\n",
      " [0.23980418 0.88955593 0.94045013 0.3894628  0.        ]\n",
      " [0.33541515 0.28967002 0.03664556 0.6518567  0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "N = np.random.rand(6,5)\n",
    "M = np.random.rand(3,3)\n",
    "M = np.array([[1,0,0],[0,0,0],[0,0,0]])\n",
    "# print(M)\n",
    "conver = Convolution()\n",
    "P_cu = conver.conv_gpu_naive(N,M)\n",
    "P_sp = convolve2d(N.astype(np.float32), M.astype(np.float32), mode='same')\n",
    "print(np.allclose(P_cu, P_sp))\n",
    "print(N,'\\n')\n",
    "print(P_cu,'\\n')\n",
    "print(P_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25858879 0.76644024 0.23690224 ... 0.10312783 0.802767   0.2767137 ]\n",
      " [0.48213143 0.43717487 0.24105782 ... 0.42669798 0.75363248 0.88913923]\n",
      " [0.96097627 0.33534357 0.14011016 ... 0.31211257 0.05761873 0.35872807]\n",
      " ...\n",
      " [0.94446634 0.94470696 0.26177127 ... 0.25845082 0.92723354 0.9162604 ]\n",
      " [0.95204508 0.47338191 0.06090975 ... 0.23428814 0.87261467 0.15879089]\n",
      " [0.05189116 0.74409996 0.25270494 ... 0.71068001 0.58741064 0.44194069]]\n",
      "[[4.37174857e-01 2.41057813e-01 7.93456316e-01 ... 7.53632486e-01\n",
      "  8.89139235e-01 0.00000000e+00]\n",
      " [3.35343570e-01 1.40110165e-01 6.23291790e-01 ... 5.76187335e-02\n",
      "  3.58728081e-01 0.00000000e+00]\n",
      " [5.04994333e-01 8.71350057e-04 1.13818854e-01 ... 6.85880005e-01\n",
      "  8.24093997e-01 0.00000000e+00]\n",
      " ...\n",
      " [4.73381907e-01 6.09097518e-02 2.18991861e-02 ... 8.72614682e-01\n",
      "  1.58790886e-01 0.00000000e+00]\n",
      " [7.44099975e-01 2.52704948e-01 7.44353354e-01 ... 5.87410629e-01\n",
      "  4.41940695e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "[[4.37174857e-01 2.41057813e-01 7.93456316e-01 ... 7.53632486e-01\n",
      "  8.89139235e-01 0.00000000e+00]\n",
      " [3.35343570e-01 1.40110165e-01 6.23291790e-01 ... 5.76187335e-02\n",
      "  3.58728081e-01 0.00000000e+00]\n",
      " [5.04994333e-01 8.71350057e-04 1.13818854e-01 ... 6.85880005e-01\n",
      "  8.24093997e-01 0.00000000e+00]\n",
      " ...\n",
      " [4.73381907e-01 6.09097518e-02 2.18991861e-02 ... 8.72614682e-01\n",
      "  1.58790886e-01 0.00000000e+00]\n",
      " [7.44099975e-01 2.52704948e-01 7.44353354e-01 ... 5.87410629e-01\n",
      "  4.41940695e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6\n",
      "(5, 6, 1)\n",
      "[[0 0 0]\n",
      " [0 1 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "N = np.random.rand(5,6)\n",
    "height, width = N.shape\n",
    "print(height, width)\n",
    "BlockDim = (*N.shape,1)\n",
    "print(BlockDim)\n",
    "M = np.array(([0,0,0],[0,1,0],[0,0,0]))\n",
    "print(M)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdf7c51fe71bae416eddcc8e429936b019ff907e8a09932761e48214d3299c84"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('cudaEnv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
